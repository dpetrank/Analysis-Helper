{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvGet(file):\n",
    "    \n",
    "    str_data = np.genfromtxt(file, delimiter=',',skip_header=1, names=True, dtype=None, encoding=None)\n",
    "    flt_data = np.genfromtxt(file, delimiter=',',skip_header=1, names=True, dtype=float)\n",
    "    \n",
    "    return str_data, flt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanityCheck1(str_data, column_title, row_number):\n",
    "    \n",
    "    print(\"Column: \"+column_title)\n",
    "    print(\"Row: \"+str(row_number))\n",
    "    print(\"Cell value: \"+str(str_data[column_title][row_number]))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retainRows(flt_data, str_data, column, category):\n",
    "    \n",
    "    # user setting to avoid filtering rows\n",
    "    if ((column is None) and (category is None)):\n",
    "        return flt_data.copy(), str_data.copy()\n",
    "    \n",
    "    # otherwise, filter rows\n",
    "    filtered_flt_data = flt_data[str_data[column] == category]\n",
    "    filtered_str_data = str_data[str_data[column] == category]\n",
    "\n",
    "    return filtered_flt_data, filtered_str_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanityCheck2(prev_data, filtered_data):\n",
    "    \n",
    "    print(\"Previous number of rows: \"+str(prev_data.shape[0]))\n",
    "    print(\"Updated number of rows: \"+str(filtered_data.shape[0]))\n",
    "    print(str(prev_data.shape[0] - filtered_data.shape[0])+\" rows removed.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumns(filtered_flt_data, filtered_str_data, y_label, stimulus_label, subjectID_label):\n",
    "\n",
    "    y_col = filtered_flt_data[y_label]\n",
    "    stimulus_col = filtered_str_data[stimulus_label]\n",
    "    subID_col = filtered_str_data[subjectID_label]\n",
    "    object_list = np.unique(filtered_str_data[stimulus_label])\n",
    "    subID_list = np.unique(filtered_str_data[subjectID_label])\n",
    "\n",
    "    return y_col, stimulus_col, subID_col, object_list, subID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(filtered_flt_data, feature_list):\n",
    "    \n",
    "    X = np.array(filtered_flt_data[feature_list].tolist())\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarify(y_col, subID_col, median):\n",
    "    \n",
    "    subject_ids, subject_indices = np.unique(subID_col, return_index=True)\n",
    "    \n",
    "    if median=='subject':\n",
    "        return binarify_subject_median(y_col, subject_indices)\n",
    "    \n",
    "    if median=='overall':\n",
    "        return binarify_overall_median(y_col)\n",
    "\n",
    "    return binary_y_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarify_subject_median(y_col, subject_indices):\n",
    "    \n",
    "    # initialize the output array \n",
    "    binary_y = np.array([])\n",
    "    \n",
    "    # loop over each subject\n",
    "    for i in range(0,len(subject_indices)):\n",
    "    \n",
    "        # get the measures given by the current subject\n",
    "        if i==len(subject_indices)-1:\n",
    "            cur_y = y_col[subject_indices[i]:]\n",
    "        else:\n",
    "            cur_y = y_col[subject_indices[i]:subject_indices[i+1]]\n",
    "            \n",
    "        # get the subject's median for the measure\n",
    "        cur_y_median = np.median(cur_y)\n",
    "        \n",
    "        # create the binary version of the vector, based on the median\n",
    "        cur_binary_y = (cur_y > cur_y_median).astype(int)\n",
    "        \n",
    "        # insert the modified binary vector to the output array\n",
    "        binary_y = np.concatenate((binary_y, cur_binary_y))\n",
    "        \n",
    "    return binary_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarify_overall_median(y_col):\n",
    "    \n",
    "    y_col_median = np.median(y_col)\n",
    "    binary_y = (y_col > y_col_median).astype(int)\n",
    "    \n",
    "    return binary_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCheck(binary_y_col):\n",
    "    \n",
    "    per_ones = int(np.mean(binary_y_col) * 100)\n",
    "    per_zeros = 100 - per_ones\n",
    "    \n",
    "    print(\"The y vector has \"+str(per_ones)+\"% 1s, and \"+str(per_zeros)+\"% zeros.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceMissingValues(X):\n",
    "    \n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    replaced_X = imp.fit_transform(X)\n",
    "    \n",
    "    return replaced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(replaced_X):\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    scaled_X = std_scaler.fit_transform(replaced_X)\n",
    "\n",
    "    return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanityCheck3(scaled_X, outlier_fraction):\n",
    "    \n",
    "    print(f\"{outlier_fraction*100} percent of the data is around {int(scaled_X.shape[0]*outlier_fraction)} outliers.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayOutliers(scaled_X, outlier_fraction):\n",
    "    \n",
    "    # get PCA components\n",
    "    pca_components = getPCA(scaled_X)\n",
    "    \n",
    "    # envelop and make the outliers\n",
    "    pca_outliers, pca_no_outliers, outliers_indices = getMapping(pca_components, outlier_fraction)\n",
    "    \n",
    "    # display the outliers\n",
    "    displayMapping(pca_outliers, pca_no_outliers)\n",
    "    \n",
    "    return outliers_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCA(scaled_X):\n",
    "    \n",
    "    # apply PCA to get 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_components = pca.fit_transform(scaled_X)\n",
    "\n",
    "    return pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMapping(pca_components, outlier_fraction):\n",
    "    \n",
    "    # create elliptic envelope\n",
    "    elenv = EllipticEnvelope(contamination=outlier_fraction)\n",
    "\n",
    "    # fit ellipsoid to the data\n",
    "    outlier_pred = elenv.fit_predict(pca_components)\n",
    "\n",
    "    # get indices with outliers\n",
    "    anom_index = (outlier_pred==-1).nonzero()[0]\n",
    "\n",
    "    # get outlier data\n",
    "    pca_outliers = pca_components[anom_index]\n",
    "\n",
    "    # get non-outlier data\n",
    "    pca_no_outliers = np.delete(pca_components, anom_index, 0)\n",
    "    \n",
    "    return pca_outliers, pca_no_outliers, anom_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayMapping(pca_outliers, pca_no_outliers):\n",
    "    \n",
    "    # visualizing the non-outliers\n",
    "    x = pca_no_outliers[:,0]\n",
    "    y = pca_no_outliers[:,1]\n",
    "\n",
    "    # visualizing the outliers\n",
    "    x_anom = pca_outliers[:,0]\n",
    "    y_anom = pca_outliers[:,1]\n",
    "\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x,y)\n",
    "    ax.scatter(x_anom, y_anom, color='r')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(outliers_indices, scaled_X, binary_y_col, y_col, stimulus_col, subID_col):\n",
    "\n",
    "    processed_X = np.delete(scaled_X, outliers_indices, 0)\n",
    "    processed_bi_y = np.delete(binary_y_col, outliers_indices, 0)\n",
    "    processed_y = np.delete(y_col, outliers_indices, 0)\n",
    "    processed_stim_col = np.delete(stimulus_col, outliers_indices, 0)\n",
    "    processed_subID_col = np.delete(subID_col, outliers_indices, 0)\n",
    "    \n",
    "    return processed_X, processed_bi_y, processed_y, processed_stim_col, processed_subID_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
